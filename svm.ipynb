{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài toán phân loại sử dụng SVM \n",
    "\n",
    "Mục tiêu: \n",
    "\n",
    "- Xây dựng được mô hình svm sử dụng thư viện sklearn. \n",
    "- Ứng dụng, hiểu cách áp dụng mô hình svm vào giải quyết bài toán thực tế (vd: phân loại văn bản) \n",
    "- Sử dụng độ đo Accuracy để làm độ đo đánh giá chất lượng mô hình. \n",
    "\n",
    "Vấn đề: \n",
    "- Có một tập các văn bản dạng text không có nhãn, làm sao để biết văn bản này là thuộc về thể loại nào, pháp luật, đời sống, văn học, thể thao ...\n",
    "- => Xây dựng mô hình học máy có thể phân loại các thể loại của văn bản chỉ dựa trên nội dung.  \n",
    "\n",
    "Dữ liệu: \n",
    "- Có tập các văn bản và nhãn tương ứng của từng văn bản trong một khoảng thời gian \n",
    "- Tập các nhãn - 10 nhãn văn bản: \n",
    "    > Giải trí, Khoa học - Công nghệ, Kinh tế, Pháp luật, Sức khỏe, Thể thao, Thời sự, Tin khác, Độc giả, Đời sống - Xã hội\n",
    "- Ví dụ văn bản nhãn **thể thao**: \n",
    "    > \"Dân_trí Real Madrid đã dẫn trước trong cả trận đấu , nhưng họ vẫn phải chấp_nhận bị Dortmund cầm hòa 2-2 ở Bernabeu . Real Madrid chấp_nhận đứng thứ_hai ở bảng F Champions League ...\"\n",
    "\n",
    "Bài toán: \n",
    "- Input: tập các từ trong văn bản 1 mẫu dữ liệu $X = [x_1, x_2, ... x_n]$\n",
    "- Output: nhãn $y$ là 1 trong 10 nhãn trên "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets.base import load_files\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.datasets.base import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dữ liệu từ thư mục đã crappy từ trước \n",
    "\n",
    "Cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_1135/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/news_vnexpress/\"\n",
    "header = \"%-20s%-30s\" % (\"Số lượng văn bản\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "total = 0\n",
    "for label in os.listdir(DATA_PATH):\n",
    "    n = len(os.listdir(os.path.join(DATA_PATH, label)))\n",
    "    total += n\n",
    "    entry = \"%-20d%-30s\" % (n, label)\n",
    "    print(entry)\n",
    "print(\"---------------------------------------------\")\n",
    "print(f'Tổng số văn bản: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_files(container_path=DATA_PATH, encoding=\"utf-8\")\n",
    "print(dir(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"%-6s %-10s\" % (\"ID\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "for id, label in enumerate(data_train.target_names):\n",
    "    print(\"%-6d %-10s\" % (id, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.data[0:2], end='\\n\\n')\n",
    "print(data_train.filenames[0:2], end='\\n\\n')\n",
    "print(data_train.target[0:2], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Kiểm tra các thông tin sau:\n",
    "    + Số lượng văn bản trong data_train.data\n",
    "    + Số lượng ids trong data_train.target\n",
    "    + Số lượng filenames trong data_train.filenames\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tiền xử lý dữ liệu đưa dữ liệu từ dạng text về dạng ma trận bằng TF-IDF\n",
    "\n",
    "- Thử nghiệm để kiểm tra hoạt động chuyển hoá dữ liệu về dạng ma trận "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]\n",
    "print(f\"Tổng số lượng từ dừng: {len(stopwords)}\")\n",
    "print(\"Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại): \", stopwords[:10])\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "Chuyển hoá dữ liệu text về dạng vector tfidf \n",
    "    - loại bỏ từ dừng\n",
    "    - sinh từ điển\n",
    "    - chuyển thành dữ liệu dạng ma trận 2 chiều kích thước n x m với n là số lượng văn bản và m là số lượng từ trong từ điển\n",
    "\"\"\"\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "print(\"5 từ đầu tiên trong từ điển:\\n\")\n",
    "i = 0\n",
    "for k,v in module_count_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 5:\n",
    "        break \n",
    "print()\n",
    "\n",
    "# Số chiều của dữ liệu \n",
    "print(f\"Số chiều của dữ liệu: {data_preprocessed.shape}\")\n",
    "print(f\"Số từ trong từ điển: {len(module_count_vector.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu thành 2 phần train_data và test_data\n",
    "- train_data chiếm 80 % dữ liệu \n",
    "- test_data chiếm 20 % dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# chia dữ liệu thành 2 phần sử dụng hàm train_test_split.\n",
    "test_size = 0.2\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split( data_preprocessed, data_train.target, test_size=test_size)\n",
    "\n",
    "\n",
    "# hiển thị một số thông tin về dữ liệu \n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Hiển thị ra id, tên nhãn của 5 văn bản đầu tiên trong tập train. \n",
    " - Gợi ý: lấy dữ liệu id từ biến y_train, mapping với thứ tự nằm trong mảng data_train.target_names\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huấn luyện mô hình SVM trên tập train_data\n",
    "\n",
    "Sử dụng thư viện sklearn để xây dựng mô hình \n",
    "- `svm.SVC(kernel='linear', C=1.0)`: chọn hàm nhân phân tách là linear, tham số C=1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Đánh giá mô hình SVM trên tập test_data\n",
    "\n",
    "Thực hiện dự đoán nhãn cho từng văn bản trong tập test \n",
    "\n",
    "Độ đo đánh giá: \n",
    "> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Thực hiện sử dụng model đã được train để suy diễn 1 văn bản mới \n",
    "- Dữ liệu mới đến ở dạng dữ liệu thô => cần tiền xử lý dữ liệu về dạng dữ_liệu_ma_trận\n",
    "- infer sử dụng hàm model.predict(dữ_liệu_ma_trận) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiền xử lý dữ liệu sử dụng module model_rf_preprocess. \n",
    "news = [\"Công_phượng ghi bàn cho đội_tuyển Việt_nam\"]\n",
    "preprocessed_news = model_rf_preprocess.transform(news)\n",
    "print(preprocessed_news, end='\\n\\n')\n",
    "pred = model.predict(preprocessed_news)\n",
    "print(pred, data_train.target_names[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bài tập bổ sung: \n",
    "\n",
    "### 4.1 Thử nghiệm các tham số \n",
    "\n",
    "- Các tham số với giá trị khác nhau có thể ảnh hưởng để kết quả học \n",
    "- Cần thử nghiệm kỹ lượng để đưa ra kết quả khách quan: tham số C, kernel.\n",
    "    - Chọn mô hình với bộ tham số cho kết quả tốt nhất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM: kernel, C\n",
    " - Gợi ý:\n",
    "     + Đầu tiên cố định C = 1.0 (có thể là giá trị khác), thay đổi kernel = {'linear', 'poly', 'rbf', 'sigmoid'}\n",
    "     + Với mỗi kernel chạy huấn luyện và đánh giá lại mô hình. Chọn kernel cho acc cao nhất.\n",
    "       Giả sử trong trường hợp này là linear\n",
    "     + Cố định kernel là linear, thay đổi C = {0.1, 1.0, 5.0, 10.0}\n",
    "     + Với mỗi giá trị C chạy huấn luện và đánh giá lại. Chọn C cho acc cao nhất.\n",
    "\"\"\"\n",
    "######################\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Phân loại số viết tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "target = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=test_size)\n",
    "\n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM với bài toán phân loại ảnh\n",
    " - Gợi ý: Làm tương tự với phân loại văn bản phía trên\n",
    "\"\"\"\n",
    "######################\n",
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
